---
title: 日志配置文档
order: 10
---

## 概述

> 1、在部署完系统之后，您需要进行日志配置操作，以便ATD可以解析您的日志，进而进行威胁分析。

> 2、在日志接入时，系统支持直接引用预置解析模板或根据日志格式手动配置解析模板。
> ATD已预置多种解析模板，可直接在日志接入时直接引用。对于未预置的日志类型需要提供原始日志，然后根据日志类型选择合适的规则进行递归式解析，直到解析出需要的结果为止。

> 3、日志对接分为三步：

    （1）日志解析模板配置，即使用预置模板，或根据原始日志手动配置模板确定日志类型、解析方式和字段映射，以便系统可以成功解析您的日志；当预置解析模板能满足您的要求时，您直接确定好使用哪个即可，这一步无需配置。

    （2）日志接入配置，选择第一步中确定好的预置模板或者手动配置好的解析模板，然后配置kafka，确定Zookeeper地址、TopicName等，以便系统知道从哪里可以获取到您推送的日志。在完成日志配置后，您需要将日志推送到Kafka相应的TopicName中。
    


## 步骤一：手动解析日志配置

目前，系统支持四种日志类型：

1、logformat

2、JSON

3、正则表达式

4、分隔符

5、组解析

请根据您实际的日志类型，添加相应的日志格式，不同日志类型的配置如下：<br/>

### 1、logformat

**（1）日志样例**

```
124.239.189.15 - [2016-07-16T15:56:04+08:00] 2ab80c0cf.yunlian.io "GET /adf/ad.php?abc=select+*+from+information_schema+where+1&testlogintest=test HTTP/1.1" 0.011 401 173 201 "-" "curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.15.3 zlib/1.2.3 libidn/1.18 libssh2/1.4.2" "-"
```
**（2）log_format字段**

对于纯文本类型的日志，只需要填写一条原始日志及相应的log_format即可，ATD规定的log_format字段名称如下表所示：

|字段名|解释|默认值|
|------|------|-------|
|*remote_addr|客户端IP地址|-|
|*request_uri|请求的uri|-|
|*http_host|请求地址（域名）|必填|
|http_x_forwarded_for|反向客户端IP地址|-|
|time_local|通用日志格式下的本地时间|-|
|status|请求返回的状态码|200|
|hostname|日志来源|-|
|remote_user|客户端用户名称|-|
|method|http请求方法|GET|
|body_bytes_sent|发送给客户端的字节数，不包括响应头的大小|0|
|bytes_sent|发送给客户端的总字节数|-|
|http_referer|记录从哪个页面链接访问过来的|-|
|http_user_agent|记录客户端浏览器相关信息|chrome|
|request_length|请求的长度（包括请求行，请求头和请求正文）|0|
|request_time|请求处理时间，单位为秒，精度毫秒|0|
|upstream_status|upstream返回的状态码信息|-|
|upstream_addr|后端upstream地址，真正提供服务的主机地址|-|
|upstream_response_time|upstream响应时间|0|

**（3）log_format格式要求**

> * 如果您的日志是文本格式，请务必使用ATD指定的字段名称定义log_format，否则ATD将无法完成日志解析；
> * 字段名以\$为前缀，例如：$remote_addr
> * 含有“*”字符的字段必须指定的字段；
> * 如果您的日志中没有http_host，您可以在配置页面上设置http_host的默认值；
> * log_format中的字段必须按顺序与原始日志中的字段一一对应，如果您的日志中包含上述字段之外的字段，可自定义名称，如：field1

**（4）配置示例**

原始日志：

```
124.239.189.15 - [2016-07-16T15:56:04+08:00] 2ab80c0cf.yunlian.io "GET /adf/ad.php?abc=select+*+from+information_schema+where+1&testlogintest=test HTTP/1.1" 0.011 401 173 201 "-" "curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.15.3 zlib/1.2.3 libidn/1.18 libssh2/1.4.2" "-"
```

log_format：

```
$remote_addr $remote_user [$time_local] $http_host "$method $request_uri $http" $request_time $status $body_bytes_sent $request_length "$http_referer" "$http_user_agent" "$http_x_forwarded_for"
```

![logformat解析]({{site.baseurl}}/images/log/parse2.png)


### 2、 JSON

**（1）日志样例**

```json
{"remote_addr":"124.239.189.115","time_local":"2017-06-29T15:25:59+08:00","scheme":"http","http_host":"yunlian.io","method":"GET","request_uri":"/adf/logining/ad.php?abc=test","request_time":"1.187","status":"200","upstream_addr":"192.168.11.207","upstream_status":"200","upstream_response_time":"1.187","request_length":"2054","body_bytes_sent":"1181","http_referer":"http://2ab80c0cf.yunlian.io/123456.html","http_user_agent":"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36","http_x_forwarded_for":"124.239.189.115","hostname":"node001131"}
```

**（2）配置示例**

> 如果您的日志如上样例所示，您只需上传一条原始日志，并在界面中设置映射关系即可。

**（3）注意事项**

> 如果是JSON格式数据，请不要格式化数据，也即是原始日志是一行完整的JSON格式数据，而不是多行格式化的数据。

![json解析]({{site.baseurl}}/images/log/parse3.png)



### 3、正则表达式
**（1）日志样例**

```
Jan 31 15:39:54 xm11-112 sshd[4187]: Received disconnect from 172.18.14.184 port 62750:11: disconnected by user
```

**（2）配置示例**

```
(?<date>\w{3}\s+\d{1,2}\s\d\d:\d\d:\d\d)\s(?<dst>\S+)\s+(?<pid>[^:]*):\s+(?<message>.*)
```

![正则解析]({{site.baseurl}}/images/log/parse4.png)


### 4、分隔符
**（1）日志样例**

```
18:21:02 [pid:123] [MOC]ip=1.1.1.1,host=bjp123,message=loginsuccess
```

**（2）配置示例**

分隔符解析方式首先进行字段分割，字段分割分为：","、"|"、":"、"&"、";"、"自定义"方式，采用分隔符解析字段分隔符必选。其次根据实际情况是否对字段分隔符解析进行K-V形式解析，K-V形式解析包括："="、":"、"自定义"。无论是分隔符或K-V都可以多段并行解析，也即是可以同时存在多个字段分隔符或K-V分隔符。
针对上述日志样例，字段分隔符采用","，K-V分隔符采用"="，如下图所示：
![分隔符解析]({{site.baseurl}}/images/log/parse5.png)


### 5、组解析
**（1）日志样例**

```
Dec 27 15:58:04 node01 node01: session(WARNING)(id=S2TGD1JJY69K4P,service=sessionReview, server=CentOS(10.10.33.30),account=root,identity=test(test),from=10.10.67.15,authorizer=admin,wait for reviewing)

Jun 27 14:33:42 node01 node01: TUILOG(INFORMATIONAL)(id=S0E56FWNPTLV66,service=tuilog, server=10.10.33.30(CentOS7),account=root,identity=admin(admin),from=10.10.66.190,action=allow,command=ls)

Dec 27 18:36:39 node01 node1: cmd(NOTICE)(id=S0R9ADXQE020K7,service=cmdcheck,action=confirm(pass), server=CentOS(10.10.33.30),account=root,identity=test(test),from=10.10.67.15,command=ls -a)

Dec 27 18:24:24 node01 node1: access(INFORMATIONAL)(id=S0IAIA8C8X3QZV,service=tuilogin,server=CentOS(10.10.33.30),account=root,identity=admin(admin),from=10.10.67.15)

Dec 27 18:20:13 node01 node1: login(WEB)(INFORMATIONAL)(service=native,identity=admin,from=10.10.67.15,login authorize success) 
```

**（2）配置示例**

组解析适用于结构复杂多样的日志。您可以上传多条不同结构的原始日志，添加解析方式为组解析。如下图所示：
![分隔符解析]({{site.baseurl}}/images/log/parse5.png)

根据这些日志的结构在组解析中添加解析方式进行配置，直到覆盖所有结构的日志。

组解析1：

解析方式：正则表达式
(?<date>\w{3}\s+\d{1,2}\s\d\d:\d\d:\d\d)\s(?<dst>\S+)\s+(?<pid>[^:]*):\s+(?<message>.*)

组解析2：

    解析方式：正则表达式
(?<datetime>\w+\s\d+\s\S+)\s+(?<hostname>\w+)\s(?<biaoshi>\w+):\s+(?<event>\w+)\((?<loglevel>\w+)\)\((?<msg>.*)\)

在对日志进行解析后，支持对解析结果进行字段调整，可进行的操作包括：
1.字段默认值设置：选择字段，并赋予其默认值
2.重命名设置：为解析字段重命名
3.删除设置：删除特定字段
4.GeoIP设置：富化完善IP地理位置
5.脚本设置：以脚本的方式对字段进行设置


## 步骤二：日志对接配置
> 在成功完成日志格式配置后，您可以对某个日志格式进行对接配置，选择使用系统的Kafka或是您私有的Kafka，在选择了您私有的Kafka后，您需要设置TopicName、Zookeeper地址或Kafka地址。


## 步骤三：推日志
> 1、在完成日志配置后，您需要将日志推送到Kafka相应的TopicName中。
【注意】请勿将不同格式的域名日志推到同一个TopicName下，否则ATD将无法完成日志解析且不能进行威胁分析。
2、在进行推日志操作时，您可以根据每个日志格式后对应的文档说明来进行推日志操作。

### 四种推日志方式介绍
系统支持多种给Kafka推送日志的方式，每种方式有推荐使用场景，以下是几种推送方式优缺点介绍：
#### 1、优先推荐Kafkacat推送方式
##### 优势：
由C语言开发，资源消耗少。

##### 劣势:
（1）推送日志文件的名称固定，有做日志切割的日志文件在切割完成后必须保持文件名不变，如nginx_access.log。
（2）不支持修改日志中的字段，只支持简单的过滤操作。

#### 2、Rsyslog推送方式
##### 优势：
由C语言开发，资源消耗少，支持通配符及新产生文件内容的推送，如/data0/logs/*.log。

##### 劣势：
（1）需要升级rsyslog以及安装rsyslog-kafka插件进行推送，可能需要下载依赖包。
（2）不支持修改日志中的字段，只支持简单的过滤操作

#### 3、Filebeat推送方式

##### 优势： 
由GO语言开发，相比于Java语言开发的logstash资源消耗少一些，可以过滤及简单的修改日志中的字段，支持通配符及新产生文件内容的推送，依赖包较少。

##### 劣势：
（1）相比于C语言开发的工具如rsyslog、kafkacat资源消耗更多一些。
（2）不能精确修改日志中的字段。

#### 4、Logstash推送方式

##### 优势： 
由Java语言开发，可精确修改日志中的字段，支持通配符及新产生文件内容的推送，依赖包较少。

##### 劣势：
资源消耗比另外几种推送工具高。
